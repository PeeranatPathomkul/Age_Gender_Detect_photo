import streamlit as st
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
import time
import os
from PIL import Image
import io
import threading
import av
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration, WebRtcMode
import base64  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô base64 string ‡πÉ‡∏ô HTML

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(
    page_title="Face Age Gender Detection",
    page_icon="üë§",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á CSS ‡∏™‡∏ß‡∏¢‡πÜ
st.markdown("""
<style>
    .main-title {
        font-size: 3rem !important;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-title {
        font-size: 1.5rem !important;
        color: #424242;
        text-align: center;
        margin-bottom: 2rem;
    }
    .result-box {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .stat-box {
        background-color: #e3f2fd;
        border-radius: 10px;
        padding: 10px 15px;
        margin: 10px 0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }
    .footer {
        text-align: center;
        margin-top: 3rem;
        color: #666;
        font-size: 0.8rem;
    }
    .stButton>button {
        background-color: #1E88E5;
        color: white;
        font-weight: bold;
        border: none;
        border-radius: 5px;
        padding: 0.5rem 1rem;
    }
    .stButton>button:hover {
        background-color: #1565C0;
    }
    .face-grid {
        display: flex;
        flex-wrap: wrap;
        gap: 10px;
        justify-content: center;
    }
    .face-card {
        border: 1px solid #ddd;
        border-radius: 8px;
        padding: 10px;
        background-color: white;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
    }
    .camera-options {
        margin-top: 10px;
        margin-bottom: 20px;
        padding: 10px;
        background-color: #f8f9fa;
        border-radius: 5px;
        border: 1px solid #e9ecef;
    }
    .camera-mode-selector {
        margin-top: 10px;
        margin-bottom: 15px;
        padding: 15px;
        background-color: #e8f5e9;
        border-radius: 8px;
        border: 1px solid #c8e6c9;
    }
    .mode-info {
        font-size: 0.9rem;
        color: #555;
        font-style: italic;
        margin-top: 5px;
    }
</style>
""", unsafe_allow_html=True)

# ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏±‡∏ß‡πÄ‡∏ß‡πá‡∏ö
st.markdown("<h1 class='main-title'>üë§ ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡πÄ‡∏û‡∏® ‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏¢‡∏∏</h1>", unsafe_allow_html=True)
st.markdown("<p class='sub-title'>‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå</p>", unsafe_allow_html=True)

# ‡∏ô‡∏¥‡∏¢‡∏≤‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô lrn (Local Response Normalization)
@st.cache_resource
def create_lrn_function():
    def lrn(x, depth_radius=5, bias=1, alpha=1, beta=0.5):
        return tf.nn.local_response_normalization(
            x, depth_radius=depth_radius, bias=bias, alpha=alpha, beta=beta
        )
    return lrn

lrn = create_lrn_function()

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ (‡πÉ‡∏ä‡πâ cache ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á)
@st.cache_resource
def load_models():
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå models ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á
    os.makedirs("models", exist_ok=True)
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏≤‡∏ò‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
    face_model_path = "opencv_face_detector_uint8.pb"
    face_proto_path = "opencv_face_detector.pbtxt"
    age_model_path = "age_model_improved.h5"
    gender_model_path = "gender_model_improved.h5"
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô
    models_exist = all([os.path.exists(p) for p in [face_model_path, face_proto_path, age_model_path, gender_model_path]])
    
    if not models_exist:
        # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡πÑ‡∏î‡πÄ‡∏£‡πá‡∏Å‡∏ó‡∏≠‡∏£‡∏µ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        current_dir_files = [f for f in os.listdir('.') if os.path.isfile(f)]
        model_files = {
            'face_model': [f for f in current_dir_files if f.endswith('_uint8.pb')],
            'face_proto': [f for f in current_dir_files if f.endswith('.pbtxt')],
            'age_model': [f for f in current_dir_files if f.startswith('age') and (f.endswith('.h5') or f.endswith('.keras'))],
            'gender_model': [f for f in current_dir_files if f.startswith('gender') and (f.endswith('.h5') or f.endswith('.keras'))]
        }
        
        if all([len(files) > 0 for files in model_files.values()]):
            # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏î‡πÄ‡∏£‡πá‡∏Å‡∏ó‡∏≠‡∏£‡∏µ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÅ‡∏ó‡∏ô
            face_model_path = model_files['face_model'][0]
            face_proto_path = model_files['face_proto'][0]
            age_model_path = model_files['age_model'][0]
            gender_model_path = model_files['gender_model'][0]
        else:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'models/' ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ô‡πÑ‡∏î‡πÄ‡∏£‡πá‡∏Å‡∏ó‡∏≠‡∏£‡∏µ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô")
            st.info("‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡∏±‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤, ‡πÑ‡∏ü‡∏•‡πå config, ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≤‡∏¢‡∏∏ ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏û‡∏®")
            return None, None, None
    
    try:
        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        faceNet = cv2.dnn.readNet(face_model_path, face_proto_path)
        
        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≤‡∏¢‡∏∏‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏®
        ageModel = load_model(age_model_path, custom_objects={'lrn': lrn})
        genderModel = load_model(gender_model_path, custom_objects={'lrn': lrn})
        
        return faceNet, ageModel, genderModel
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: {e}")
        return None, None, None

# ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏¢‡∏∏‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ
ageList = ['0-2 years', '4-6 years', '8-12 years', '15-20 years', '25-32 years', '38-43 years', '48-53 years', '60-100 years']
genderList = ['Female', 'Male']

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
def highlightFace(net, frame, conf_threshold=0.7):
    frameOpencvDnn = frame.copy()
    frameHeight = frameOpencvDnn.shape[0]
    frameWidth = frameOpencvDnn.shape[1]
    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)

    net.setInput(blob)
    detections = net.forward()
    faceBoxes = []
    
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > conf_threshold:
            x1 = int(detections[0, 0, i, 3] * frameWidth)
            y1 = int(detections[0, 0, i, 4] * frameHeight)
            x2 = int(detections[0, 0, i, 5] * frameWidth)
            y2 = int(detections[0, 0, i, 6] * frameHeight)
            faceBoxes.append([x1, y1, x2, y2])
            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)
    
    return frameOpencvDnn, faceBoxes

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö preprocess ‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≤‡∏¢‡∏∏
def preprocess_for_age_model(face_img):
    try:
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≤‡∏¢‡∏∏
        face_resized = cv2.resize(face_img, (224, 224))
        # Normalize ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á [0, 1]
        face_normalized = face_resized.astype("float") / 255.0
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥‡πÅ‡∏£‡∏Å (batch dimension)
        face_batch = np.expand_dims(face_normalized, axis=0)
        return face_batch
    except Exception as e:
        st.error(f"Error in age preprocessing: {e}")
        return None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö preprocess ‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏®
def preprocess_for_gender_model(face_img):
    try:
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏®
        face_resized = cv2.resize(face_img, (224, 224))  # CaffeNet ‡πÉ‡∏ä‡πâ input size 227x227
        # Normalize ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á [0, 1]
        face_normalized = face_resized.astype("float") / 255.0
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥‡πÅ‡∏£‡∏Å (batch dimension)
        face_batch = np.expand_dims(face_normalized, axis=0)
        return face_batch
    except Exception as e:
        st.error(f"Error in gender preprocessing: {e}")
        return None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏û‡∏®‡πÅ‡∏ö‡∏ö‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡∏ä‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏ç‡∏¥‡∏á
def predict_binary_gender(gender_preds):
    female_conf = gender_preds[0][0]  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏´‡∏ç‡∏¥‡∏á (index 0)
    male_conf = gender_preds[0][1]    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡∏≤‡∏¢ (index 1)
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏û‡∏®‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏´‡∏ç‡∏¥‡∏á
    if female_conf > male_conf:
        gender_idx = 0  # Female
        confidence = female_conf * 100
    else:
        gender_idx = 1  # Male
        confidence = male_conf * 100
    
    gender = genderList[gender_idx]
    return gender, confidence

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏î‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô
def extract_face_with_fixed_size(frame, face_box, padding=20, target_size=(200, 200)):
    try:
        x1, y1, x2, y2 = face_box
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        face_center_x = (x1 + x2) // 2
        face_center_y = (y1 + y2) // 2
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏î‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°)
        face_size = max(x2 - x1, y2 - y1)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° padding
        face_size_with_padding = face_size + 2 * padding
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏à‡∏±‡∏ï‡∏∏‡∏£‡∏±‡∏™
        new_x1 = max(0, face_center_x - face_size_with_padding // 2)
        new_y1 = max(0, face_center_y - face_size_with_padding // 2)
        new_x2 = min(frame.shape[1] - 1, face_center_x + face_size_with_padding // 2)
        new_y2 = min(frame.shape[0] - 1, face_center_y + face_size_with_padding // 2)
        
        # ‡∏ï‡∏±‡∏î‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        face = frame[new_y1:new_y2, new_x1:new_x2]
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏†‡∏≤‡∏û‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if face.size == 0 or face.shape[0] == 0 or face.shape[1] == 0:
            return None, None
            
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö target_size
        face_resized = cv2.resize(face, target_size)
        
        return face_resized, (new_x1, new_y1, new_x2, new_y2)
        
    except Exception as e:
        st.error(f"Error extracting face: {e}")
        return None, None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≤‡∏¢‡∏∏‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏®
def process_image(img, faceNet, ageModel, genderModel, confidence_threshold=0.7):
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏à‡∏≤‡∏Å PIL ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô OpenCV (RGB to BGR)
    frame = np.array(img)
    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    resultImg, faceBoxes = highlightFace(faceNet, frame, conf_threshold=confidence_threshold)
    
    if not faceBoxes:
        return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), [], "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û"
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    faces_data = []
    
    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    for i, faceBox in enumerate(faceBoxes):
        # ‡∏ï‡∏±‡∏î‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î
        standardized_face, new_face_coords = extract_face_with_fixed_size(frame, faceBox, padding=20)
        
        if standardized_face is None:
            continue
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        face_for_age = preprocess_for_age_model(standardized_face)
        face_for_gender = preprocess_for_gender_model(standardized_face)
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏û‡∏® (‡πÉ‡∏ä‡πâ genderModel)
        gender_preds = genderModel.predict(face_for_gender, verbose=0) if face_for_gender is not None else None
        if gender_preds is not None:
            gender, gender_confidence = predict_binary_gender(gender_preds)
        else:
            gender = "Unknown"
            gender_confidence = 0
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≤‡∏¢‡∏∏ (‡πÉ‡∏ä‡πâ ageModel)
        age_preds = ageModel.predict(face_for_age, verbose=0) if face_for_age is not None else None
        if age_preds is not None:
            age_idx = np.argmax(age_preds)
            if age_idx < len(ageList):
                age = ageList[age_idx]
                age_confidence = age_preds[0][age_idx] * 100
            else:
                age = "Unknown"
                age_confidence = 0
        else:
            age = "Unknown"
            age_confidence = 0
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏ô‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        x1, y1, x2, y2 = faceBox
        label = f"{gender} ({gender_confidence:.1f}%), {age} ({age_confidence:.1f}%)"
        cv2.putText(resultImg, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 
                    0.6, (0, 255, 255), 2, cv2.LINE_AA)
        
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        face_data = {
            "face_img": cv2.cvtColor(standardized_face, cv2.COLOR_BGR2RGB),
            "gender": gender,
            "gender_confidence": gender_confidence,
            "age": age,
            "age_confidence": age_confidence,
            "box": faceBox
        }
        faces_data.append(face_data)
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô RGB ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô Streamlit
    result_rgb = cv2.cvtColor(resultImg, cv2.COLOR_BGR2RGB)
    
    message = f"‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(faces_data)} ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤"
    return result_rgb, faces_data, message

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏≠‡∏¢‡∏π‡πà
@st.cache_data(ttl=300)  # cache for 5 minutes
def get_available_cameras():
    available_cameras = []
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà index 0 ‡∏ñ‡∏∂‡∏á 9 (‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°)
    for i in range(10):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            ret, _ = cap.read()
            if ret:
                # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡πâ‡∏≠‡∏á (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ)
                camera_name = f"Camera #{i}"
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                if width > 0 and height > 0:
                    camera_name += f" ({width}x{height})"
                available_cameras.append((i, camera_name))
            cap.release()
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    if not available_cameras:
        available_cameras = [(0, "Default Camera")]
    
    return available_cameras

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå
def process_webcam_frame(frame, faceNet, ageModel, genderModel, confidence_threshold=0.7):
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏†‡∏≤‡∏û‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if frame is None:
        return None, []
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô OpenCV BGR
    img = np.copy(frame)
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    resultImg, faceBoxes = highlightFace(faceNet, img, conf_threshold=confidence_threshold)
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏¥‡∏°
    if not faceBoxes:
        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB), []
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    faces_data = []
    
    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    for i, faceBox in enumerate(faceBoxes):
        # ‡∏ï‡∏±‡∏î‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î
        standardized_face, new_face_coords = extract_face_with_fixed_size(img, faceBox, padding=20)
        
        if standardized_face is None:
            continue
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        face_for_age = preprocess_for_age_model(standardized_face)
        face_for_gender = preprocess_for_gender_model(standardized_face)
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏û‡∏® (‡πÉ‡∏ä‡πâ genderModel)
        gender_preds = genderModel.predict(face_for_gender, verbose=0) if face_for_gender is not None else None
        if gender_preds is not None:
            gender, gender_confidence = predict_binary_gender(gender_preds)
        else:
            gender = "Unknown"
            gender_confidence = 0
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≤‡∏¢‡∏∏ (‡πÉ‡∏ä‡πâ ageModel)
        age_preds = ageModel.predict(face_for_age, verbose=0) if face_for_age is not None else None
        if age_preds is not None:
            age_idx = np.argmax(age_preds)
            if age_idx < len(ageList):
                age = ageList[age_idx]
                age_confidence = age_preds[0][age_idx] * 100
            else:
                age = "Unknown"
                age_confidence = 0
        else:
            age = "Unknown"
            age_confidence = 0
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏ô‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        x1, y1, x2, y2 = faceBox
        label = f"{gender} ({gender_confidence:.1f}%), {age} ({age_confidence:.1f}%)"
        cv2.putText(resultImg, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 
                    0.6, (0, 255, 255), 2, cv2.LINE_AA)
        
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        face_data = {
            "face_img": cv2.cvtColor(standardized_face, cv2.COLOR_BGR2RGB),
            "gender": gender,
            "gender_confidence": gender_confidence,
            "age": age,
            "age_confidence": age_confidence,
            "box": faceBox
        }
        faces_data.append(face_data)
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô RGB ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô Streamlit
    result_rgb = cv2.cvtColor(resultImg, cv2.COLOR_BGR2RGB)
    
    return result_rgb, faces_data

# Callback function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö video_processor
def video_frame_callback(frame):
    img = frame.to_ndarray(format="rgb24")
    
    # ‡πÉ‡∏ä‡πâ Session State ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ confidence_threshold
    confidence_threshold = st.session_state.get('confidence_threshold', 0.7)
    
    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏ü‡∏£‡∏°
    result_frame, _ = process_webcam_frame(
        img, 
        st.session_state.faceNet, 
        st.session_state.ageModel, 
        st.session_state.genderModel, 
        confidence_threshold
    )
    
    return av.VideoFrame.from_ndarray(result_frame, format="rgb24")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á sidebar ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
st.sidebar.title("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
confidence_threshold = st.sidebar.slider(
    "‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤", 
    min_value=0.0, 
    max_value=1.0, 
    value=0.7, 
    step=0.05,
    help="‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô ‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ô‡πâ‡∏≠‡∏¢‡∏•‡∏á"
)

# ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ confidence_threshold ‡πÉ‡∏ô session state
st.session_state['confidence_threshold'] = confidence_threshold

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
mode = st.sidebar.radio("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô", ["‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û", "‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏°"])

# ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
with st.sidebar.expander("‚ÑπÔ∏è ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô"):
    st.markdown("""
    ‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Deep Learning ‡πÄ‡∏û‡∏∑‡πà‡∏≠:
    - ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ OpenCV DNN
    - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏û‡∏®‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏á‡∏≠‡∏≤‡∏¢‡∏∏
    - ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à
    
    **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏î‡πâ
    """)

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
faceNet, ageModel, genderModel = load_models()

# ‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô session state ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô callback function
st.session_state.faceNet = faceNet
st.session_state.ageModel = ageModel
st.session_state.genderModel = genderModel

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
if faceNet is None or ageModel is None or genderModel is None:
    st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'models' ‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:")
    st.code("""
    Age_Gender_Detect_photo/
    ‚îú‚îÄ‚îÄ opencv_face_detector_uint8.pb  # ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    ‚îú‚îÄ‚îÄ opencv_face_detector.pbtxt    # ‡πÑ‡∏ü‡∏•‡πå config ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    ‚îú‚îÄ‚îÄ age_model_improved.h5         # ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≤‡∏¢‡∏∏
    ‚îî‚îÄ‚îÄ gender_model_improved.h5      # ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏û‡∏®
    """)
    st.stop()

# ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏Ñ‡∏±‡πà‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏±‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
st.markdown("<hr>", unsafe_allow_html=True)

# ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏ï‡∏≤‡∏°‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
if mode == "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û":
    uploaded_file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û", type=["jpg", "jpeg", "png"])
    
    if uploaded_file is not None:
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û..."):
            # ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            image = Image.open(uploaded_file)
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            st.image(image, caption="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö", use_column_width=True)
            
            # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            result_img, faces_data, message = process_image(image, faceNet, ageModel, genderModel, confidence_threshold)
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
            st.markdown(f"### ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: {message}")
            
            if len(faces_data) > 0:
                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                st.image(result_img, caption="‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤", use_container_width=True)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                st.markdown("### ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤")
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á grid ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                st.markdown("<div class='face-grid'>", unsafe_allow_html=True)
                
                # ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)
                cols = st.columns(min(3, len(faces_data)))
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                for i, face_data in enumerate(faces_data):
                    col_idx = i % min(3, len(faces_data))
                    
                    with cols[col_idx]:
                        st.image(face_data["face_img"], caption=f"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà {i+1}", width=200)
                        
                        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                        st.markdown("<div class='stat-box'>", unsafe_allow_html=True)
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏®‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏¢‡∏∏‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à
                        st.markdown(f"**‡πÄ‡∏û‡∏®:** {face_data['gender']} ({face_data['gender_confidence']:.1f}%)")
                        st.markdown(f"**‡∏≠‡∏≤‡∏¢‡∏∏:** {face_data['age']} ({face_data['age_confidence']:.1f}%)")
                        
                        st.markdown("</div>", unsafe_allow_html=True)
                
                st.markdown("</div>", unsafe_allow_html=True)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                result_img_pil = Image.fromarray(result_img)
                buf = io.BytesIO()
                result_img_pil.save(buf, format="JPEG")
                byte_img = buf.getvalue()
                
                st.download_button(
                    label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå",
                    data=byte_img,
                    file_name="result.jpg",
                    mime="image/jpeg",
                )

else:  # ‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏°
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
    available_cameras = get_available_cameras()
    camera_options = [f"{cam_name}" for _, cam_name in available_cameras]
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á
    st.markdown("<div class='camera-options'>", unsafe_allow_html=True)
    st.subheader("üé• ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á")
    
    selected_camera_name = st.selectbox(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:",
        options=camera_options,
        index=0
    )
    
    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ index ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    selected_camera_index = 0
    for idx, name in available_cameras:
        if name == selected_camera_name:
            selected_camera_index = idx
            break
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á
    st.markdown("<div class='camera-mode-selector'>", unsafe_allow_html=True)
    st.subheader("üì∑ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á")
    
    camera_mode = st.radio(
        "‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:",
        options=["‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡πà‡∏≠‡∏¢ detect", "detect ‡πÉ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏ö‡∏ö real-time"],
        index=0
    )
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏´‡∏°‡∏î
    if camera_mode == "‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡πà‡∏≠‡∏¢ detect":
        st.markdown("<p class='mode-info'>‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏∂‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡πÄ‡∏û‡∏® ‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏¢‡∏∏</p>", unsafe_allow_html=True)
    else:
        st.markdown("<p class='mode-info'>‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡πÄ‡∏û‡∏® ‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏¢‡∏∏‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå</p>", unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)
    
    # ‡πÄ‡∏Å‡πá‡∏ö camera index ‡πÅ‡∏•‡∏∞ camera mode ‡πÉ‡∏ô session state
    if 'camera_index' not in st.session_state:
        st.session_state.camera_index = selected_camera_index
    
    if 'camera_mode' not in st.session_state:
        st.session_state.camera_mode = camera_mode
    
    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï camera index ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
    if st.session_state.camera_index != selected_camera_index:
        st.session_state.camera_index = selected_camera_index
        # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á
        if 'camera_image' in st.session_state:
            st.session_state.pop('camera_image')
    
    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï camera mode ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
    if st.session_state.camera_mode != camera_mode:
        st.session_state.camera_mode = camera_mode
        # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏´‡∏°‡∏î
        if 'camera_image' in st.session_state:
            st.session_state.pop('camera_image')
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    if camera_mode == "‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡πà‡∏≠‡∏¢ detect":
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á
        camera_col1, camera_col2 = st.columns(2)
        
        with camera_col1:
            start_camera = st.button("üì∏ ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û", key="start_camera")
        
        with camera_col2:
            process_button = st.button("üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û", key="process_image")
            
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á
        if start_camera or ('camera_active' in st.session_state and st.session_state.camera_active):
            st.session_state.camera_active = True
            
            # ‡πÉ‡∏ä‡πâ st.camera_input ‡πÇ‡∏î‡∏¢‡∏£‡∏∞‡∏ö‡∏∏ camera_index
            try:
                camera_image = st.camera_input(
                    "‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏°",
                    key=f"camera_{selected_camera_index}",
                    disabled=False,
                    help="‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤"
                )
                
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢‡πÑ‡∏ß‡πâ‡πÉ‡∏ô session state
                if camera_image is not None:
                    st.session_state.camera_image = camera_image
                    
            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á: {e}")
                st.info("‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏≠‡∏∑‡πà‡∏ô‡∏≠‡∏¢‡∏π‡πà")
        
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢‡πÑ‡∏ß‡πâ ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        if process_button and 'camera_image' in st.session_state:
            camera_image = st.session_state.camera_image
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û..."):
                try:
                    # ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
                    image = Image.open(camera_image)
                    
                    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
                    result_img, faces_data, message = process_image(image, faceNet, ageModel, genderModel, confidence_threshold)
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                    st.markdown(f"### ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: {message}")
                    
                    if len(faces_data) > 0:
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                        st.image(result_img, caption="‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤", use_column_width=True)
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                        st.markdown("### ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤")
                        
                        # ‡∏™‡∏£‡πâ‡∏≤‡∏á grid ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                        cols = st.columns(min(3, len(faces_data)))
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                        for i, face_data in enumerate(faces_data):
                            col_idx = i % min(3, len(faces_data))
                            
                            with cols[col_idx]:
                                st.image(face_data["face_img"], caption=f"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà {i+1}", width=200)
                                
                                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                                st.markdown("<div class='stat-box'>", unsafe_allow_html=True)
                                
                                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏®‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏¢‡∏∏‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à
                                st.markdown(f"**‡πÄ‡∏û‡∏®:** {face_data['gender']} ({face_data['gender_confidence']:.1f}%)")
                                st.markdown(f"**‡∏≠‡∏≤‡∏¢‡∏∏:** {face_data['age']} ({face_data['age_confidence']:.1f}%)")
                                
                                st.markdown("</div>", unsafe_allow_html=True)
                        
                        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                        result_img_pil = Image.fromarray(result_img)
                        buf = io.BytesIO()
                        result_img_pil.save(buf, format="JPEG")
                        byte_img = buf.getvalue()
                        
                        st.download_button(
                            label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå",
                            data=byte_img,
                            file_name="result.jpg",
                            mime="image/jpeg",
                        )
                except Exception as e:
                    st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û: {e}")
                    st.info("‡∏•‡∏≠‡∏á‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
        
        # ‡∏õ‡∏∏‡πà‡∏°‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏Å‡∏•‡πâ‡∏≠‡∏á
        if 'camera_active' in st.session_state and st.session_state.camera_active:
            if st.button("üîÑ ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏Å‡∏•‡πâ‡∏≠‡∏á", key="reset_camera"):
                # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏•‡πâ‡∏≠‡∏á
                if 'camera_image' in st.session_state:
                    st.session_state.pop('camera_image')
                st.session_state.camera_active = False
                st.experimental_rerun()
    
    # ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î real-time ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡∏°‡πà
    else:  # ‡πÇ‡∏´‡∏°‡∏î detect ‡πÉ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏ö‡∏ö real-time
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á placeholder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        status_placeholder = st.empty()
        frame_placeholder = st.empty()  # placeholder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á
        result_placeholder = st.empty()  # placeholder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        
        # ‡∏õ‡∏∏‡πà‡∏°‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        col1, col2 = st.columns(2)
        with col1:
            start_button = st.button("‚ñ∂Ô∏è ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå", type="primary")
        with col2:
            stop_button = st.button("‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö", type="secondary")
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        if start_button:
            st.session_state.realtime_active = True
        if stop_button:
            st.session_state.realtime_active = False
            
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        if not 'realtime_active' in st.session_state:
            st.session_state.realtime_active = False
            
        if st.session_state.realtime_active:
            status_placeholder.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå...")
            
            try:
                # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á
                frameWidth = 640
                frameHeight = 480
                brightness = 180
                
                # ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á
                cap = cv2.VideoCapture(selected_camera_index)
                cap.set(3, frameWidth)
                cap.set(4, frameHeight)
                cap.set(10, brightness)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if not cap.isOpened():
                    status_placeholder.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏•‡πâ‡∏≠‡∏á")
                    st.session_state.realtime_active = False
                else:
                    # ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ ‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏´‡∏¢‡∏∏‡∏î
                    while st.session_state.realtime_active:
                        success, img = cap.read()
                        if not success:
                            status_placeholder.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ")
                            break
                        
                        # ‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏µ‡∏à‡∏≤‡∏Å BGR ‡πÄ‡∏õ‡πá‡∏ô RGB
                        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                        
                        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û
                        result_img, faces_data, message = process_image(
                            Image.fromarray(img_rgb), 
                            faceNet, 
                            ageModel, 
                            genderModel, 
                            confidence_threshold
                        )
                        
                        # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
                        status_placeholder.success(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå... ‡∏û‡∏ö {len(faces_data)} ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤")
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö (‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡∏ó‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏î‡∏¥‡∏°)
                        frame_placeholder.image(result_img, caption="‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå", use_column_width=True)
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡∏ó‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏î‡∏¥‡∏°)
                        # ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡∏ó‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏î‡∏¥‡∏°)
                        # Replace the existing block:
                        if len(faces_data) > 0:
                            st.markdown("<h3 style='color: white; text-align: left;'>üë§ ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤</h3>", unsafe_allow_html=True)
                            
                            # Delete the entire `face_html` generation block
                            
                            # Instead, you can add a simple text display if you want any output
                            for i, face_data in enumerate(faces_data):
                                st.write(f"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà {i+1}: {face_data['gender']} ({face_data['gender_confidence']:.1f}%), {face_data['age']} ({face_data['age_confidence']:.1f}%)")
                        else:
                            # Ensure result_placeholder is cleared
                            result_placeholder.empty()
                        
                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏´‡∏¢‡∏∏‡∏î
                        if not st.session_state.realtime_active:
                            break
                            
                        # ‡∏£‡∏≠‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ CPU ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
                        time.sleep(0.03)
                    
                # ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á
                cap.release()
                status_placeholder.info("‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡πâ‡∏ß")
                
            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå: {e}")
                st.session_state.realtime_active = False
        else:
            status_placeholder.info("‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏° '‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

# ‡πÅ‡∏™‡∏î‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ó‡πâ‡∏≤‡∏¢‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå
st.markdown("<div class='footer'>Face Age Gender Detection App | ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Streamlit ‡πÅ‡∏•‡∏∞ OpenCV</div>", unsafe_allow_html=True)