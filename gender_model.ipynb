{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create output folder for all model files and results\n",
    "OUTPUT_FOLDER = 'model7_gender_only'\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Input, Concatenate\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50V2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sns\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "NUM_CLASSES_GENDER = 2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# 1. Data preparation\n",
    "data_parent = 'C:/Users/focus/copy_age_gender_mo2/all_path'  # Adjust path as needed\n",
    "\n",
    "# Load data from all folds\n",
    "data = pd.read_csv(os.path.join(data_parent, 'fold_0_data.txt'), sep='\\t')\n",
    "data1 = pd.read_csv(os.path.join(data_parent, 'fold_1_data.txt'), sep='\\t')\n",
    "data2 = pd.read_csv(os.path.join(data_parent, 'fold_2_data.txt'), sep='\\t')\n",
    "data3 = pd.read_csv(os.path.join(data_parent, 'fold_3_data.txt'), sep='\\t')\n",
    "data4 = pd.read_csv(os.path.join(data_parent, 'fold_4_data.txt'), sep='\\t')\n",
    "\n",
    "# Combine all data\n",
    "total_data = pd.concat([data, data1, data2, data3, data4], ignore_index=True)\n",
    "\n",
    "# Create image paths\n",
    "img_path = []\n",
    "for row in total_data.iterrows():\n",
    "    path = os.path.join(data_parent, \"faces\", row[1].user_id, \n",
    "                    f\"coarse_tilt_aligned_face.{str(row[1].face_id)}.{row[1].original_image}\")\n",
    "    img_path.append(path)\n",
    "\n",
    "df = total_data[['gender', 'x', 'y', 'dx', 'dy']].copy()\n",
    "df['img_path'] = img_path\n",
    "\n",
    "# Clean data - remove problematic rows\n",
    "df = df.dropna()\n",
    "unbiased_data = df[df.gender != 'u'].copy()\n",
    "\n",
    "# Save data for reference\n",
    "unbiased_data.to_csv(os.path.join(OUTPUT_FOLDER, 'clean_data.csv'), index=False)\n",
    "\n",
    "# Label mappings\n",
    "gender_to_label_map = {\n",
    "    'f': 0,\n",
    "    'm': 1\n",
    "}\n",
    "\n",
    "# Reverse mappings for prediction interpretation\n",
    "label_to_gender_map = {0: 'Female', 1: 'Male'}\n",
    "\n",
    "# Convert to numerical labels\n",
    "unbiased_data['gender_label'] = unbiased_data['gender'].apply(lambda g: gender_to_label_map[g])\n",
    "\n",
    "# 2. Data analysis for imbalance\n",
    "def analyze_data_imbalance():\n",
    "    print(\"Data Imbalance Analysis:\")\n",
    "    \n",
    "    print(\"\\nGender Distribution:\")\n",
    "    gender_counts = unbiased_data['gender'].value_counts()\n",
    "    print(gender_counts)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(data=unbiased_data, x='gender')\n",
    "    plt.title('Gender Distribution')\n",
    "    plt.xlabel('Gender')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(ticks=[0, 1], labels=['Female (f)', 'Male (m)'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_FOLDER, 'gender_distribution.png'))\n",
    "    \n",
    "    return gender_counts\n",
    "\n",
    "# 3. Enhanced image loading and preprocessing\n",
    "def load_and_preprocess_image(img_path, augment=False):\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            return np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Enhanced face detection and alignment could be added here\n",
    "        \n",
    "        # Better preprocessing with histogram equalization for improved contrast\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_gray_eq = cv2.equalizeHist(img_gray)\n",
    "        img = cv2.cvtColor(img_gray_eq, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # More aggressive data augmentation\n",
    "        if augment:\n",
    "            # Random rotation\n",
    "            if np.random.random() > 0.5:\n",
    "                angle = np.random.uniform(-25, 25)  # Increased range\n",
    "                height, width = img.shape[:2]\n",
    "                matrix = cv2.getRotationMatrix2D((width/2, height/2), angle, 1)\n",
    "                img = cv2.warpAffine(img, matrix, (width, height))\n",
    "            \n",
    "            # Random brightness and contrast adjustment\n",
    "            if np.random.random() > 0.5:\n",
    "                alpha = np.random.uniform(0.7, 1.3)  # Contrast (increased range)\n",
    "                beta = np.random.uniform(-20, 20)  # Brightness (increased range)\n",
    "                img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "            \n",
    "            # Random horizontal flip\n",
    "            if np.random.random() > 0.5:\n",
    "                img = cv2.flip(img, 1)\n",
    "                \n",
    "            # Random zoom\n",
    "            if np.random.random() > 0.7:\n",
    "                zoom_factor = np.random.uniform(0.8, 1.2)\n",
    "                h, w = img.shape[:2]\n",
    "                h_new, w_new = int(h * zoom_factor), int(w * zoom_factor)\n",
    "                h_start = max(0, (h_new - h) // 2)\n",
    "                w_start = max(0, (w_new - w) // 2)\n",
    "                \n",
    "                if zoom_factor < 1:\n",
    "                    # Zoom out\n",
    "                    img_new = np.zeros((h_new, w_new, 3), dtype=np.uint8)\n",
    "                    img_new[h_start:h_start+min(h, h_new), w_start:w_start+min(w, w_new)] = img[:min(h, h_new-h_start), :min(w, w_new-w_start)]\n",
    "                    img = cv2.resize(img_new, (h, w))\n",
    "                else:\n",
    "                    # Zoom in\n",
    "                    img = img[max(0, (h-h_new)//2):min(h, (h+h_new)//2), max(0, (w-w_new)//2):min(w, (w+w_new)//2)]\n",
    "                    img = cv2.resize(img, (h, w))\n",
    "                \n",
    "            # Random noise\n",
    "            if np.random.random() > 0.8:\n",
    "                noise = np.random.normal(0, 5, img.shape).astype(np.uint8)\n",
    "                img = cv2.add(img, noise)\n",
    "                \n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {img_path}: {e}\")\n",
    "        return np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
    "\n",
    "# 4. Improved balanced data generator\n",
    "def balanced_data_generator(img_paths, labels, batch_size=32, augment=True):\n",
    "    num_samples = len(img_paths)\n",
    "    \n",
    "    # Compute class weights for better balancing\n",
    "    y_integers = labels.values\n",
    "    class_weights_array = class_weight.compute_class_weight(\n",
    "        'balanced', \n",
    "        classes=np.unique(y_integers), \n",
    "        y=y_integers\n",
    "    )\n",
    "    class_weights = dict(enumerate(class_weights_array))\n",
    "    \n",
    "    # Create indices for each class\n",
    "    class_indices = {}\n",
    "    for cls in np.unique(y_integers):\n",
    "        class_indices[cls] = np.where(y_integers == cls)[0]\n",
    "    \n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        # Sample balanced classes\n",
    "        samples_per_class = batch_size // len(class_indices)\n",
    "        remainder = batch_size % len(class_indices)\n",
    "        \n",
    "        for cls, indices in class_indices.items():\n",
    "            n_samples = samples_per_class + (1 if remainder > 0 else 0)\n",
    "            remainder -= 1 if remainder > 0 else 0\n",
    "            \n",
    "            if len(indices) < n_samples:\n",
    "                # If not enough samples, use replacement\n",
    "                sampled_indices = np.random.choice(indices, size=n_samples, replace=True)\n",
    "            else:\n",
    "                sampled_indices = np.random.choice(indices, size=n_samples, replace=False)\n",
    "            \n",
    "            for idx in sampled_indices:\n",
    "                img = load_and_preprocess_image(img_paths.iloc[idx], augment=augment)\n",
    "                batch_images.append(img)\n",
    "                batch_labels.append(labels.iloc[idx])\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        batch_images = np.array(batch_images) / 255.0\n",
    "        \n",
    "        # one-hot encoding\n",
    "        batch_labels = to_categorical(batch_labels, NUM_CLASSES_GENDER)\n",
    "        \n",
    "        yield batch_images, batch_labels\n",
    "\n",
    "# 5. Gender model with residual connections and more regularization\n",
    "def create_gender_model():\n",
    "    # Using ResNet50V2 which has better feature extraction for facial attributes\n",
    "    base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "    # Freeze early layers\n",
    "    for layer in base_model.layers[:-30]:  # Freeze fewer layers for better fine-tuning\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Input for additional features if needed\n",
    "    input_img = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "    # Extract features\n",
    "    x = base_model(input_img)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Add more regularization\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    predictions = Dense(NUM_CLASSES_GENDER, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=predictions)\n",
    "    \n",
    "    # Lower learning rate and added weight decay\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.00005, decay=1e-6)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 6. Train gender model with more robust approach\n",
    "def train_gender_model():\n",
    "    # Split data for training and testing with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        unbiased_data['img_path'],\n",
    "        unbiased_data['gender_label'],\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=unbiased_data['gender_label']\n",
    "    )\n",
    "    \n",
    "    # Print split information\n",
    "    print(f\"Training data: {len(X_train)} samples\")\n",
    "    print(f\"Testing data: {len(X_test)} samples\")\n",
    "    \n",
    "    # Calculate class weights for imbalanced data\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "    \n",
    "    # Create model\n",
    "    model = create_gender_model()\n",
    "    \n",
    "    # Create callbacks with better settings\n",
    "    checkpoint = ModelCheckpoint(os.path.join(OUTPUT_FOLDER, 'gender_model_best.h5'),\n",
    "                                monitor='val_accuracy',\n",
    "                                save_best_only=True,\n",
    "                                verbose=1)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "                                  patience=20,  # More patience\n",
    "                                  verbose=1,\n",
    "                                  restore_best_weights=True)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                 factor=0.1,  # More aggressive reduction\n",
    "                                 patience=10,  # More patience\n",
    "                                 min_lr=0.000001,\n",
    "                                 verbose=1)\n",
    "    \n",
    "    # Create generators\n",
    "    train_generator = balanced_data_generator(X_train, y_train, BATCH_SIZE, augment=True)\n",
    "    validation_generator = balanced_data_generator(X_test, y_test, BATCH_SIZE, augment=False)\n",
    "    \n",
    "    # Train model\n",
    "    steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "    validation_steps = len(X_test) // BATCH_SIZE\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=[checkpoint, early_stopping, reduce_lr],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    model.save(os.path.join(OUTPUT_FOLDER, 'gender_model_final.h5'))\n",
    "    \n",
    "    # Plot performance\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "    plt.title('Gender Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title('Gender Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_FOLDER, 'gender_model_training.png'))\n",
    "    \n",
    "    # Evaluate model with test data\n",
    "    print(\"\\nGender Model Evaluation:\")\n",
    "    \n",
    "    # Load best model\n",
    "    model = load_model(os.path.join(OUTPUT_FOLDER, 'gender_model_best.h5'))\n",
    "    \n",
    "    # Generate predictions for test data\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for i in range(0, len(X_test), BATCH_SIZE):\n",
    "        batch_img_paths = X_test.iloc[i:i+BATCH_SIZE]\n",
    "        batch_true_labels = y_test.iloc[i:i+BATCH_SIZE]\n",
    "        \n",
    "        batch_images = []\n",
    "        for img_path in batch_img_paths:\n",
    "            img = load_and_preprocess_image(img_path)\n",
    "            batch_images.append(img)\n",
    "        \n",
    "        batch_images = np.array(batch_images) / 255.0\n",
    "        batch_preds = model.predict(batch_images)\n",
    "        batch_pred_labels = np.argmax(batch_preds, axis=1)\n",
    "        \n",
    "        predictions.extend(batch_pred_labels)\n",
    "        true_labels.extend(batch_true_labels)\n",
    "    \n",
    "    # Create evaluation report\n",
    "    print(classification_report(true_labels, predictions, \n",
    "                               target_names=['Female', 'Male']))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=['Female', 'Male'],\n",
    "               yticklabels=['Female', 'Male'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Gender Prediction Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_FOLDER, 'gender_confusion_matrix.png'))\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# 7. Prediction function for gender only\n",
    "def predict_gender(image_path, gender_model):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return \"Cannot read image\"\n",
    "    \n",
    "    # Detect faces\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # Create result image\n",
    "    result_img = img.copy()\n",
    "    \n",
    "    # Process each detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        x1, y1, x2, y2 = x, y, x+w, y+h\n",
    "        \n",
    "        # Crop face\n",
    "        face_img = img[y1:y2, x1:x2]\n",
    "        \n",
    "        # Check if face is valid\n",
    "        if face_img.size == 0 or face_img.shape[0] == 0 or face_img.shape[1] == 0:\n",
    "            continue\n",
    "        \n",
    "        # Resize for model prediction\n",
    "        face_resized = cv2.resize(face_img, (IMG_SIZE, IMG_SIZE))\n",
    "        face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)\n",
    "        face_rgb = face_rgb / 255.0\n",
    "        face_rgb = np.expand_dims(face_rgb, axis=0)\n",
    "        \n",
    "        # Predict gender\n",
    "        gender_pred = gender_model.predict(face_rgb)\n",
    "        gender_class = np.argmax(gender_pred[0])\n",
    "        gender_prob = np.max(gender_pred[0]) * 100\n",
    "        gender_label = label_to_gender_map[gender_class]\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(result_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Add prediction results to image\n",
    "        label_text = f\"Gender: {gender_label} ({gender_prob:.1f}%)\"\n",
    "        cv2.putText(result_img, label_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # Save result image\n",
    "    result_path = os.path.join(OUTPUT_FOLDER, 'result_' + os.path.basename(image_path))\n",
    "    cv2.imwrite(result_path, result_img)\n",
    "    \n",
    "    return result_path\n",
    "\n",
    "# 8. Test with image function\n",
    "def test_with_image(image_path):\n",
    "    \"\"\"\n",
    "    Test gender model with image and display result\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(\"Cannot read image\")\n",
    "        return\n",
    "    \n",
    "    # Detect faces\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # Create result image\n",
    "    result_img = img.copy()\n",
    "    \n",
    "    # Load model\n",
    "    gender_model = load_model(os.path.join(OUTPUT_FOLDER, 'gender_model_best.h5'))\n",
    "    \n",
    "    # Process each detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Crop face\n",
    "        face_img = img[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize\n",
    "        face_resized = cv2.resize(face_img, (IMG_SIZE, IMG_SIZE))\n",
    "        face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)\n",
    "        face_rgb = face_rgb / 255.0\n",
    "        face_rgb = np.expand_dims(face_rgb, axis=0)\n",
    "        \n",
    "        # Predict\n",
    "        gender_pred = gender_model.predict(face_rgb)\n",
    "        gender_class = np.argmax(gender_pred[0])\n",
    "        gender_prob = np.max(gender_pred[0]) * 100\n",
    "        gender_label = label_to_gender_map[gender_class]\n",
    "        \n",
    "        # Draw bounding box and labels\n",
    "        cv2.rectangle(result_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        label_text = f\"Gender: {gender_label} ({gender_prob:.1f}%)\"\n",
    "        cv2.putText(result_img, label_text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # Save and display result\n",
    "    result_path = os.path.join(OUTPUT_FOLDER, 'result_' + os.path.basename(image_path))\n",
    "    cv2.imwrite(result_path, result_img)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title('Gender Prediction Result')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_FOLDER, 'prediction_result.png'))\n",
    "    \n",
    "    return result_path\n",
    "\n",
    "# 9. Main function\n",
    "def main():\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Gender Prediction from Face\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Analyze data\n",
    "    print(\"\\n1. Analyzing data...\")\n",
    "    gender_counts = analyze_data_imbalance()\n",
    "    print(\"\\nData Summary:\")\n",
    "    print(f\"Total samples: {len(unbiased_data)}\")\n",
    "    print(f\"Number of gender classes: {NUM_CLASSES_GENDER}\")\n",
    "    \n",
    "    # 2. Train gender model\n",
    "    print(\"\\n2. Training gender model...\")\n",
    "    gender_model, gender_history = train_gender_model()\n",
    "    \n",
    "    # 3. Test with image\n",
    "    test_img = \"C:/Users/focus/Pictures/USE_to_test_ml/image_th.png\"\n",
    "    result_path = test_with_image(test_img)\n",
    "    \n",
    "    print(f\"\\nPrediction completed. Result saved at: {result_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
