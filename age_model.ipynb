{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ปรับปรุงโมเดลทำนายอายุเพื่อแก้ปัญหา Overfitting\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Input, Attention, Add\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB2, ResNet50V2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "# สร้างโฟลเดอร์สำหรับเก็บผลลัพธ์ - เปลี่ยนเป็น model82\n",
    "OUTPUT_FOLDER = 'model82'\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "# กำหนดค่าคงที่ - ปรับเพียงเล็กน้อยจากโมเดลเดิม\n",
    "IMG_SIZE = 144  # ปรับขึ้นเพียงเล็กน้อยจาก 128 เดิม\n",
    "BATCH_SIZE = 32  # คงเดิมตามโมเดลเก่า\n",
    "EPOCHS = 40  # คงเดิมตามโมเดลเก่า\n",
    "NUM_CLASSES_AGE = 8\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ตัวแปรสำหรับ path ของข้อมูล\n",
    "data_parent = 'C:/Users/focus/copy_age_gender_mo2/all_path'  # ปรับตาม path ของคุณ\n",
    "\n",
    "# อ่านข้อมูลจากทุก fold\n",
    "data = pd.read_csv(os.path.join(data_parent, 'fold_0_data.txt'), sep='\\t')\n",
    "data1 = pd.read_csv(os.path.join(data_parent, 'fold_1_data.txt'), sep='\\t')\n",
    "data2 = pd.read_csv(os.path.join(data_parent, 'fold_2_data.txt'), sep='\\t')\n",
    "data3 = pd.read_csv(os.path.join(data_parent, 'fold_3_data.txt'), sep='\\t')\n",
    "data4 = pd.read_csv(os.path.join(data_parent, 'fold_4_data.txt'), sep='\\t')\n",
    "\n",
    "# รวมข้อมูลทั้งหมด\n",
    "total_data = pd.concat([data, data1, data2, data3, data4], ignore_index=True)\n",
    "\n",
    "# สร้าง path ของรูปภาพ\n",
    "img_path = []\n",
    "for row in total_data.iterrows():\n",
    "    path = os.path.join(data_parent, \"faces\", row[1].user_id, \n",
    "                    f\"coarse_tilt_aligned_face.{str(row[1].face_id)}.{row[1].original_image}\")\n",
    "    img_path.append(path)\n",
    "\n",
    "# สร้าง DataFrame สำหรับการเทรนโมเดล\n",
    "df = total_data[['age', 'gender', 'x', 'y', 'dx', 'dy']].copy()\n",
    "df['img_path'] = img_path\n",
    "\n",
    "# การแบ่งช่วงอายุ\n",
    "age_mapping = [('(0, 2)', '0-2'), ('2', '0-2'), ('3', '0-2'), ('(4, 6)', '4-6'), \n",
    "               ('(8, 12)', '8-13'), ('13', '8-13'), ('22', '15-20'), ('(8, 23)','15-20'), \n",
    "               ('23', '25-32'), ('(15, 20)', '15-20'), ('(25, 32)', '25-32'), \n",
    "               ('(27, 32)', '25-32'), ('32', '25-32'), ('34', '25-32'), ('29', '25-32'), \n",
    "               ('(38, 42)', '38-43'), ('35', '38-43'), ('36', '38-43'), ('42', '48-53'), \n",
    "               ('45', '38-43'), ('(38, 43)', '38-43'), ('(38, 42)', '38-43'), \n",
    "               ('(38, 48)', '48-53'), ('46', '48-53'), ('(48, 53)', '48-53'), \n",
    "               ('55', '48-53'), ('56', '48-53'), ('(60, 100)', '60+'), \n",
    "               ('57', '60+'), ('58', '60+')]\n",
    "\n",
    "age_mapping_dict = {each[0]: each[1] for each in age_mapping}\n",
    "\n",
    "# คัดกรองข้อมูลที่มีปัญหา\n",
    "drop_indices = [idx for idx, val in enumerate(df.age) \n",
    "                if val == 'None' or pd.isna(val) or val not in age_mapping_dict]\n",
    "\n",
    "# แปลงค่าอายุ\n",
    "for idx, each in enumerate(df.age):\n",
    "    if idx not in drop_indices and each in age_mapping_dict:\n",
    "        df.loc[idx, 'age'] = age_mapping_dict[each]\n",
    "\n",
    "# ลบแถวที่มีปัญหา\n",
    "df = df.drop(labels=drop_indices, axis=0)\n",
    "\n",
    "# ลบค่า NaN และเพศที่ไม่ทราบ\n",
    "df = df.dropna()\n",
    "unbiased_data = df[df.gender != 'u'].copy()\n",
    "\n",
    "# บันทึกข้อมูลสำหรับอ้างอิง\n",
    "unbiased_data.to_csv(os.path.join(OUTPUT_FOLDER, 'clean_data.csv'), index=False)\n",
    "\n",
    "# การแมป label\n",
    "age_to_label_map = {\n",
    "    '0-2': 0,\n",
    "    '4-6': 1,\n",
    "    '8-13': 2,\n",
    "    '15-20': 3,\n",
    "    '25-32': 4,\n",
    "    '38-43': 5,\n",
    "    '48-53': 6,\n",
    "    '60+': 7\n",
    "}\n",
    "\n",
    "# แมปย้อนกลับสำหรับการแปลผลลัพธ์\n",
    "label_to_age_map = {value: key for key, value in age_to_label_map.items()}\n",
    "\n",
    "# แปลงเป็น numerical labels\n",
    "unbiased_data['age_label'] = unbiased_data['age'].apply(lambda age: age_to_label_map[age])\n",
    "\n",
    "# ฟังก์ชั่นสำหรับวิเคราะห์ความไม่สมดุลของข้อมูล\n",
    "def analyze_age_data_imbalance():\n",
    "    print(\"Age Data Distribution Analysis:\")\n",
    "    age_counts = unbiased_data['age'].value_counts()\n",
    "    print(age_counts)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.countplot(data=unbiased_data, x='age', order=age_counts.index)\n",
    "    plt.title('Age Distribution')\n",
    "    plt.xlabel('Age Range')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_FOLDER, 'age_distribution.png'))\n",
    "    \n",
    "    return age_counts\n",
    "\n",
    "# ปรับปรุงฟังก์ชั่นโหลดและประมวลผลภาพที่มีการ augmentation ที่หลากหลายมากขึ้น\n",
    "def load_and_preprocess_image_for_age(img_path, augment=False):\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            return np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
    "        \n",
    "        # ปรับปรุงภาพด้วย histogram equalization แยกตามช่องสี\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        l_channel, a_channel, b_channel = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        cl = clahe.apply(l_channel)\n",
    "        merged = cv2.merge((cl, a_channel, b_channel))\n",
    "        img = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "        \n",
    "        # ปรับขนาดภาพ\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # การเพิ่มคุณภาพภาพ (Data Augmentation)\n",
    "        if augment:\n",
    "            # หมุนภาพ - เพิ่มช่วงการหมุนให้มากขึ้น\n",
    "            if np.random.random() > 0.5:\n",
    "                angle = np.random.uniform(-20, 20)  # เพิ่มช่วงการหมุน\n",
    "                height, width = img.shape[:2]\n",
    "                matrix = cv2.getRotationMatrix2D((width/2, height/2), angle, 1)\n",
    "                img = cv2.warpAffine(img, matrix, (width, height))\n",
    "            \n",
    "            # ปรับความสว่างและคอนทราสต์ - เพิ่มช่วงให้มากขึ้น\n",
    "            if np.random.random() > 0.4:  # เพิ่มโอกาสการเกิด\n",
    "                alpha = np.random.uniform(0.7, 1.3)  # เพิ่มช่วงคอนทราสต์\n",
    "                beta = np.random.uniform(-15, 15)    # เพิ่มช่วงความสว่าง\n",
    "                img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "            \n",
    "            # สลับภาพแนวนอน\n",
    "            if np.random.random() > 0.5:\n",
    "                img = cv2.flip(img, 1)\n",
    "            \n",
    "            # การเลื่อนภาพ - เพิ่มช่วงการเลื่อน\n",
    "            if np.random.random() > 0.4:\n",
    "                tx = np.random.uniform(-15, 15)  # เพิ่มช่วงการเลื่อน\n",
    "                ty = np.random.uniform(-15, 15)\n",
    "                translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "                img = cv2.warpAffine(img, translation_matrix, (IMG_SIZE, IMG_SIZE))\n",
    "            \n",
    "            # เพิ่มสัญญาณรบกวน (noise)\n",
    "            if np.random.random() > 0.6:  # เพิ่มโอกาสการเกิด\n",
    "                noise_type = np.random.choice(['gaussian', 'salt_pepper'])\n",
    "                if noise_type == 'gaussian':\n",
    "                    noise = np.random.normal(0, 5, img.shape).astype(np.uint8)  # เพิ่มความเข้มของ noise\n",
    "                    img = cv2.add(img, noise)\n",
    "                else:\n",
    "                    # Salt and pepper noise\n",
    "                    s_vs_p = 0.5\n",
    "                    amount = 0.01\n",
    "                    # Salt\n",
    "                    num_salt = np.ceil(amount * img.size * s_vs_p)\n",
    "                    coords = [np.random.randint(0, i - 1, int(num_salt)) for i in img.shape]\n",
    "                    img[coords[0], coords[1], :] = 255\n",
    "                    # Pepper\n",
    "                    num_pepper = np.ceil(amount * img.size * (1. - s_vs_p))\n",
    "                    coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in img.shape]\n",
    "                    img[coords[0], coords[1], :] = 0\n",
    "                \n",
    "            # เทคนิค Cutout ที่ปรับปรุง\n",
    "            if np.random.random() > 0.7:\n",
    "                num_cutouts = np.random.randint(1, 3)  # อาจมีมากกว่า 1 cutout\n",
    "                for _ in range(num_cutouts):\n",
    "                    h, w = img.shape[:2]\n",
    "                    mask_size_h = int(h * np.random.uniform(0.05, 0.2))  # เพิ่มขนาดสูงสุด\n",
    "                    mask_size_w = int(w * np.random.uniform(0.05, 0.2))\n",
    "                    \n",
    "                    # สุ่มตำแหน่งที่จะตัด\n",
    "                    top = np.random.randint(0, h - mask_size_h)\n",
    "                    left = np.random.randint(0, w - mask_size_w)\n",
    "                    \n",
    "                    # สร้างพื้นที่สีดำหรือสีเฉลี่ย\n",
    "                    if np.random.random() > 0.5:\n",
    "                        img[top:top+mask_size_h, left:left+mask_size_w, :] = 0\n",
    "                    else:\n",
    "                        # ใช้สีเฉลี่ยแทน\n",
    "                        img[top:top+mask_size_h, left:left+mask_size_w, :] = img.mean(axis=(0,1))\n",
    "                \n",
    "            # เพิ่ม MixUp (แบบง่าย) สำหรับช่วงอายุที่มีตัวอย่างน้อย (48-53 และ 60+)\n",
    "            # จำเป็นต้องทำในระดับ generator ไม่ใช่ในฟังก์ชั่นนี้ แต่ระบุเป็นความเห็น\n",
    "                \n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {img_path}: {e}\")\n",
    "        return np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
    "\n",
    "# สร้าง Focal Loss เพื่อให้ความสำคัญกับคลาสที่ทำนายยาก\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = 1e-9\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = alpha * y_true * tf.pow(1 - y_pred, gamma)\n",
    "        loss = weight * cross_entropy\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# ฟังก์ชั่น Learning Rate Scheduler ด้วย Cosine Annealing\n",
    "def cosine_annealing_scheduler(epoch, total_epochs=EPOCHS, initial_lr=0.0001, min_lr=1e-6):\n",
    "    return min_lr + (initial_lr - min_lr) * (1 + math.cos(math.pi * epoch / total_epochs)) / 2\n",
    "\n",
    "# ฟังก์ชั่นสร้าง Data Generator ที่สมดุลสำหรับข้อมูลอายุ\n",
    "def balanced_age_data_generator(img_paths, labels, batch_size=24, augment=True):\n",
    "    num_samples = len(img_paths)\n",
    "    \n",
    "    # คำนวณน้ำหนักสำหรับแต่ละคลาส\n",
    "    y_integers = labels.values\n",
    "    class_weights_array = class_weight.compute_class_weight(\n",
    "        'balanced', \n",
    "        classes=np.unique(y_integers), \n",
    "        y=y_integers\n",
    "    )\n",
    "    class_weights = dict(enumerate(class_weights_array))\n",
    "    \n",
    "    # สร้าง indices สำหรับแต่ละคลาส\n",
    "    class_indices = {}\n",
    "    for cls in np.unique(y_integers):\n",
    "        class_indices[cls] = np.where(y_integers == cls)[0]\n",
    "    \n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        # สุ่มเลือกข้อมูลแบบสมดุล\n",
    "        samples_per_class = batch_size // len(class_indices)\n",
    "        remainder = batch_size % len(class_indices)\n",
    "        \n",
    "        for cls, indices in class_indices.items():\n",
    "            # เพิ่มจำนวนตัวอย่างสำหรับคลาสที่ยากต่อการทำนาย (6, 7)\n",
    "            boost_factor = 1.0\n",
    "            if cls in [6, 7]:  # คลาส 48-53 และ 60+\n",
    "                boost_factor = 1.5\n",
    "                \n",
    "            n_samples = int(samples_per_class * boost_factor) + (1 if remainder > 0 else 0)\n",
    "            remainder -= 1 if remainder > 0 else 0\n",
    "            \n",
    "            if len(indices) < n_samples:\n",
    "                # ถ้ามีตัวอย่างไม่พอ ให้สุ่มซ้ำ\n",
    "                sampled_indices = np.random.choice(indices, size=n_samples, replace=True)\n",
    "            else:\n",
    "                sampled_indices = np.random.choice(indices, size=n_samples, replace=False)\n",
    "            \n",
    "            for idx in sampled_indices:\n",
    "                img = load_and_preprocess_image_for_age(img_paths.iloc[idx], augment=augment)\n",
    "                batch_images.append(img)\n",
    "                batch_labels.append(labels.iloc[idx])\n",
    "        \n",
    "        # แปลงเป็น numpy arrays\n",
    "        batch_images = np.array(batch_images) / 255.0\n",
    "        \n",
    "        # แปลงเป็น one-hot encoding\n",
    "        batch_labels = to_categorical(batch_labels, NUM_CLASSES_AGE)\n",
    "        \n",
    "        yield batch_images, batch_labels\n",
    "\n",
    "# ปรับปรุงโมเดลทำนายอายุใหม่\n",
    "def create_improved_age_model():\n",
    "    # กลับไปใช้ ResNet50V2 เหมือนเดิม แต่ปรับการโหลด weights และ input size\n",
    "    base_model = ResNet50V2(\n",
    "        weights='imagenet', \n",
    "        include_top=False, \n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # ล็อคชั้นฟีเจอร์ส่วนแรกๆ เพื่อรักษาฟีเจอร์พื้นฐาน\n",
    "    # ล็อคน้อยลงจากเดิมเพื่อให้โมเดลเรียนรู้ได้มากขึ้น\n",
    "    freeze_layers = 50  # ล็อคเพียง 50 เลเยอร์แรกเท่านั้น\n",
    "    \n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # สร้างโมเดล\n",
    "    input_img = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "    # รับฟีเจอร์จาก base model\n",
    "    x = base_model(input_img)\n",
    "    \n",
    "    # Global Average Pooling ช่วยลดจำนวนพารามิเตอร์และลด overfitting\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # เพิ่ม regularization และ normalization\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # ลดความซับซ้อนของเน็ตเวิร์คลง แต่ไม่ให้มาก regularization จนเกินไป\n",
    "    x = Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4),  # ใช้ regularization ที่ไม่มากเกินไป\n",
    "        activity_regularizer=l1_l2(l1=1e-5, l2=1e-4)\n",
    "    )(x)\n",
    "    x = Dropout(0.4)(x)  # ใช้ dropout rate ที่ไม่มากเกินไป\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(\n",
    "        64, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)\n",
    "    )(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # Output layer - ไม่เปลี่ยนแปลง\n",
    "    predictions = Dense(NUM_CLASSES_AGE, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=predictions)\n",
    "    \n",
    "    # ใช้ learning rate เริ่มต้นที่มากขึ้นเพื่อเรียนรู้ได้เร็วขึ้น\n",
    "    optimizer = Adam(learning_rate=0.0002)  # เพิ่มจาก 0.0001 เดิม\n",
    "    \n",
    "    # ยังคงใช้ categorical_crossentropy เพื่อให้สอดคล้องกับโมเดลเดิม\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ฟังก์ชั่นเทรนโมเดลอายุที่ปรับปรุงแล้ว\n",
    "def train_improved_age_model():\n",
    "    # แบ่งข้อมูลสำหรับการเทรนและทดสอบแบบมีการ stratify\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        unbiased_data['img_path'],\n",
    "        unbiased_data['age_label'],\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=unbiased_data['age_label']\n",
    "    )\n",
    "    \n",
    "    # แสดงข้อมูลการแบ่ง\n",
    "    print(f\"Training data: {len(X_train)} samples\")\n",
    "    print(f\"Testing data: {len(X_test)} samples\")\n",
    "    \n",
    "    # คำนวณ class weights สำหรับข้อมูลที่ไม่สมดุล\n",
    "    # เพิ่มน้ำหนักสำหรับคลาสที่มีตัวอย่างน้อย\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    \n",
    "    # เพิ่มน้ำหนักให้กับคลาสที่ยากต่อการทำนาย (48-53, 60+)\n",
    "    for i in [6, 7]:  # คลาส 48-53 และ 60+\n",
    "        if i in range(len(class_weights)):\n",
    "            class_weights[i] *= 1.5  # เพิ่มน้ำหนัก 50%\n",
    "    \n",
    "    class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "    \n",
    "    # สร้างโมเดล\n",
    "    model = create_improved_age_model()\n",
    "    \n",
    "    # สร้าง callbacks\n",
    "    # บันทึกโมเดลที่ดีที่สุดโดยพิจารณาจาก val_loss\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        os.path.join(OUTPUT_FOLDER, 'age_model_best.h5'),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # ปรับ early stopping - ใช้ค่าความอดทนที่เหมาะสม\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # ใช้ ReduceLROnPlateau แทน cosine annealing เพื่อให้ปรับ LR ตามการพัฒนาของโมเดล\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,  # ลด learning rate มากขึ้นเมื่อไม่มีการปรับปรุง\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # สร้าง generators\n",
    "    train_generator = balanced_age_data_generator(X_train, y_train, BATCH_SIZE, augment=True)\n",
    "    validation_generator = balanced_age_data_generator(X_test, y_test, BATCH_SIZE, augment=False)\n",
    "    \n",
    "    # เทรนโมเดล\n",
    "    steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "    validation_steps = len(X_test) // BATCH_SIZE\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=[checkpoint, early_stopping, reduce_lr],\n",
    "        class_weight=class_weight_dict,\n",
    "        validation_freq=1\n",
    "    )\n",
    "    \n",
    "    # บันทึกโมเดลสุดท้าย\n",
    "    model.save(os.path.join(OUTPUT_FOLDER, 'age_model_final.h5'))\n",
    "    \n",
    "    # สร้างกราฟแสดงผลการเทรน\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "    plt.title('Age Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title('Age Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_FOLDER, 'age_model_training.png'))\n",
    "    \n",
    "    # ประเมินโมเดลกับข้อมูลทดสอบ\n",
    "    print(\"\\nAge Model Evaluation:\")\n",
    "    \n",
    "    # โหลดโมเดลที่ดีที่สุด\n",
    "    model = load_model(os.path.join(OUTPUT_FOLDER, 'age_model_best.h5'))\n",
    "    \n",
    "    # สร้าง predictions สำหรับข้อมูลทดสอบ - ปรับปรุงวิธีการประเมิน\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    class_probabilities = {}  # เก็บความน่าจะเป็นของแต่ละคลาส\n",
    "    \n",
    "    # สร้าง dict สำหรับเก็บความน่าจะเป็น\n",
    "    for cls in range(NUM_CLASSES_AGE):\n",
    "        class_probabilities[cls] = []\n",
    "    \n",
    "    # สุ่มเลือกตัวอย่างเพื่อประหยัดเวลาในการประเมิน\n",
    "    test_indices = np.random.choice(len(X_test), min(1000, len(X_test)), replace=False)\n",
    "    \n",
    "    for idx in test_indices:\n",
    "        img_path = X_test.iloc[idx]\n",
    "        true_label = y_test.iloc[idx]\n",
    "        \n",
    "        img = load_and_preprocess_image_for_age(img_path)\n",
    "        img = np.expand_dims(img, axis=0) / 255.0\n",
    "        \n",
    "        pred = model.predict(img, verbose=0)\n",
    "        pred_label = np.argmax(pred[0])\n",
    "        \n",
    "        # เก็บผลลัพธ์\n",
    "        predictions.append(pred_label)\n",
    "        true_labels.append(true_label)\n",
    "        \n",
    "        # เก็บความน่าจะเป็นของแต่ละคลาส\n",
    "        for cls in range(NUM_CLASSES_AGE):\n",
    "            class_probabilities[cls].append(pred[0][cls])\n",
    "    \n",
    "    # สร้างรายงานการประเมิน\n",
    "    age_categories = list(age_to_label_map.keys())\n",
    "    print(classification_report(true_labels, predictions, \n",
    "                               target_names=age_categories))\n",
    "    \n",
    "    # สร้าง confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "               xticklabels=age_categories,\n",
    "               yticklabels=age_categories)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Age Prediction Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_FOLDER, 'age_confusion_matrix.png'))\n",
    "    \n",
    "    # สร้างกราฟแสดงความน่าจะเป็นเฉลี่ยของแต่ละคลาส\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    avg_probabilities = [np.mean(class_probabilities[cls]) for cls in range(NUM_CLASSES_AGE)]\n",
    "    sns.barplot(x=age_categories, y=avg_probabilities)\n",
    "    plt.title('Average Prediction Confidence by Age Group')\n",
    "    plt.xlabel('Age Group')\n",
    "    plt.ylabel('Average Confidence')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_FOLDER, 'age_prediction_confidence.png'))\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# ฟังก์ชั่นทำนายอายุจากภาพ\n",
    "def predict_age(image_path, model):\n",
    "    \"\"\"\n",
    "    ทำนายอายุจากภาพใบหน้า\n",
    "    \"\"\"\n",
    "    # อ่านภาพ\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return \"Cannot read image\"\n",
    "    \n",
    "    # ตรวจจับใบหน้า\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # สร้างภาพผลลัพธ์\n",
    "    result_img = img.copy()\n",
    "    \n",
    "    # ประมวลผลแต่ละใบหน้าที่ตรวจพบ\n",
    "    for (x, y, w, h) in faces:\n",
    "        x1, y1, x2, y2 = x, y, x+w, y+h\n",
    "        \n",
    "        # ตัดภาพใบหน้า\n",
    "        face_img = img[y1:y2, x1:x2]\n",
    "        \n",
    "        # ตรวจสอบว่าใบหน้าถูกต้อง\n",
    "        if face_img.size == 0 or face_img.shape[0] == 0 or face_img.shape[1] == 0:\n",
    "            continue\n",
    "        \n",
    "        # ปรับปรุงภาพใบหน้า\n",
    "        lab = cv2.cvtColor(face_img, cv2.COLOR_BGR2LAB)\n",
    "        l_channel, a_channel, b_channel = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        cl = clahe.apply(l_channel)\n",
    "        merged = cv2.merge((cl, a_channel, b_channel))\n",
    "        enhanced_face = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "        \n",
    "        # ปรับขนาดสำหรับการทำนาย\n",
    "        face_resized = cv2.resize(enhanced_face, (IMG_SIZE, IMG_SIZE))\n",
    "        face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)\n",
    "        face_rgb = face_rgb / 255.0\n",
    "        face_rgb = np.expand_dims(face_rgb, axis=0)\n",
    "        \n",
    "        # ทำนายอายุ\n",
    "        age_pred = model.predict(face_rgb, verbose=0)\n",
    "        age_class = np.argmax(age_pred[0])\n",
    "        age_prob = np.max(age_pred[0]) * 100\n",
    "        \n",
    "        age_label = label_to_age_map[age_class]\n",
    "        \n",
    "        # วาดกรอบ\n",
    "        cv2.rectangle(result_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # เพิ่มผลลัพธ์ลงในภาพ\n",
    "        label_text = f\"Age: {age_label} ({age_prob:.1f}%)\"\n",
    "        cv2.putText(result_img, label_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # บันทึกภาพผลลัพธ์\n",
    "    result_path = os.path.join(OUTPUT_FOLDER, 'result_' + os.path.basename(image_path))\n",
    "    cv2.imwrite(result_path, result_img)\n",
    "    \n",
    "    return result_path\n",
    "\n",
    "# ฟังก์ชั่นทดสอบด้วยภาพ\n",
    "def test_with_image(image_path, model=None):\n",
    "    \"\"\"\n",
    "    ทดสอบโมเดลกับภาพและแสดงผลลัพธ์\n",
    "    \"\"\"\n",
    "    # อ่านภาพ\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(\"Cannot read image\")\n",
    "        return\n",
    "    \n",
    "    # ตรวจจับใบหน้า\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # สร้างภาพผลลัพธ์\n",
    "    result_img = img.copy()\n",
    "    \n",
    "    # โหลดโมเดล (ถ้าไม่ได้ระบุ)\n",
    "    if model is None:\n",
    "        model = load_model(os.path.join(OUTPUT_FOLDER, 'age_model_best.h5'))\n",
    "    \n",
    "    # ประมวลผลแต่ละใบหน้าที่ตรวจพบ\n",
    "    for (x, y, w, h) in faces:\n",
    "        # ตัดภาพใบหน้า\n",
    "        face_img = img[y:y+h, x:x+w]\n",
    "        \n",
    "        # ปรับปรุงภาพใบหน้า\n",
    "        lab = cv2.cvtColor(face_img, cv2.COLOR_BGR2LAB)\n",
    "        l_channel, a_channel, b_channel = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        cl = clahe.apply(l_channel)\n",
    "        merged = cv2.merge((cl, a_channel, b_channel))\n",
    "        enhanced_face = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "        \n",
    "        # ปรับขนาด\n",
    "        face_resized = cv2.resize(enhanced_face, (IMG_SIZE, IMG_SIZE))\n",
    "        face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)\n",
    "        face_rgb = face_rgb / 255.0\n",
    "        face_rgb = np.expand_dims(face_rgb, axis=0)\n",
    "        \n",
    "        # ทำนาย\n",
    "        age_pred = model.predict(face_rgb, verbose=0)\n",
    "        age_class = np.argmax(age_pred[0])\n",
    "        age_prob = np.max(age_pred[0]) * 100\n",
    "        \n",
    "        age_label = label_to_age_map[age_class]\n",
    "        \n",
    "        # วาดกรอบและป้ายกำกับ\n",
    "        cv2.rectangle(result_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        label_text = f\"Age: {age_label} ({age_prob:.1f}%)\"\n",
    "        cv2.putText(result_img, label_text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # บันทึกและแสดงผลลัพธ์\n",
    "    result_path = os.path.join(OUTPUT_FOLDER, 'result_' + os.path.basename(image_path))\n",
    "    cv2.imwrite(result_path, result_img)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title('Age Prediction Result')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_FOLDER, 'prediction_result.png'))\n",
    "    \n",
    "    return result_path\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Improved Age Prediction from Face (Anti-Overfitting) - model82\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. วิเคราะห์ข้อมูล\n",
    "    print(\"\\n1. Analyzing age data...\")\n",
    "    age_counts = analyze_age_data_imbalance()\n",
    "    print(\"\\nData Summary:\")\n",
    "    print(f\"Total samples: {len(unbiased_data)}\")\n",
    "    print(f\"Number of age classes: {NUM_CLASSES_AGE}\")\n",
    "    \n",
    "    # 2. เทรนโมเดลอายุที่ปรับปรุงแล้ว\n",
    "    print(\"\\n2. Training improved age model...\")\n",
    "    age_model, age_history = train_improved_age_model()\n",
    "    \n",
    "    # 3. ทดสอบกับภาพ\n",
    "    test_img = \"C:/Users/focus/Pictures/USE_to_test_ml/image_th.png\"  # แก้ไขเป็น path ของภาพที่ต้องการทดสอบ\n",
    "    result_path = test_with_image(test_img, age_model)\n",
    "    \n",
    "    print(f\"\\nPrediction completed. Result saved at: {result_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
